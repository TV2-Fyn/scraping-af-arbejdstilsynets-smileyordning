{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c38ea9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer relevante biblioteker\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "# def check_at_smiley(lower, upper):\n",
    "\n",
    "#     errors = []\n",
    "\n",
    "#     # Definer en header, der bliver sendt med GET-request\n",
    "#     header = {\n",
    "#             \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36\"\n",
    "#         }\n",
    "\n",
    "#     # Sti til Arbejdstilsynets smiley-side\n",
    "#     url = \"https://websmiley.at.dk/websmiley/advancedsearchform.aspx\"\n",
    "\n",
    "#     # Send GET-request og hent Arbejdstilsynets smiley-side\n",
    "\n",
    "#     try:\n",
    "#         r = requests.get(url,headers=header,timeout=8)\n",
    "#         r.raise_for_status()\n",
    "#     except requests.exceptions.HTTPError as error:\n",
    "#         errors.append(error)\n",
    "\n",
    "\n",
    "#     # Hvis status er OK parser scriptet indholdet, henter formData og tilføjer det til et dictionary\n",
    "#     if r.status_code == 200:\n",
    "#         soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        \n",
    "#         viewstate = soup.select(\"#__VIEWSTATE\")[0]['value']\n",
    "#         eventvalidation = soup.select(\"#__EVENTVALIDATION\")[0]['value']\n",
    "           \n",
    "#         formData = {\n",
    "#             '__EVENTVALIDATION': eventvalidation,\n",
    "#             '__VIEWSTATE': viewstate,\n",
    "#             '__EVENTTARGET': '',\n",
    "#             'companyName': 'Virksomhedens navn',\n",
    "#             'cvrNr': 'CVR-nr.',\n",
    "#             'pNr': 'P-nr.',\n",
    "#             'ddlBrancheGrupper':0,\n",
    "#             'ddlRegioner': 0,\n",
    "#             'ddlSmiley':0,\n",
    "#             'btnDownload': 'Download smileydata'   \n",
    "#         }\n",
    "        \n",
    "        \n",
    "#     # Send POST-request, hvor den netop hentede formdata sendes med\n",
    "#     try:\n",
    "#         r = requests.post(url, data=formData, headers=header)\n",
    "#         r.raise_for_status()\n",
    "#     except requests.exceptions.HTTPError as error:\n",
    "#         errors.append(error)\n",
    "\n",
    "#     try:\n",
    "\n",
    "#         # Konverter responsdata til en string og indlæs i en DataFrame\n",
    "#         # filtrer datasæt efter fynske virksomheder og røde smileyer\n",
    "#         text = r.text\n",
    "#         df = pd.read_csv(StringIO(text),sep=\";\",keep_default_na=False)\n",
    "#         new = df\n",
    "#         # Rens kolonnenavne for mellemrum og filtrer efter røde smileyer på fyn\n",
    "#         new.columns = new.columns.str.replace(\" \",\"\")\n",
    "#         new = new[(new[\"POSTNR\"] > lower) & (new[\"POSTNR\"] < upper) & (new[\"SMILEY\"] == \"rød\")]\n",
    "\n",
    "#         # Fjern duplikerede rækker, sorter efter navn \n",
    "#         # Lav ID-kolonne for det nye datasætaml alle IDs i en liste\n",
    "#         new = new.drop_duplicates()\n",
    "#         new = new.sort_values(\"NAVN\")\n",
    "#         new[\"id\"] = new[list(new.columns)].astype(str).sum(axis=1).map(hash)\n",
    "#         new = new.reset_index(drop=True)\n",
    "#         new_smiley_ids = list(dict.fromkeys(list(new[\"id\"])))\n",
    "#     except:\n",
    "#         print(\"There was an error adding IDs to new dataset\")\n",
    "\n",
    "#     # Forsøg at indlæse tidligere datasæt i en dataframe\n",
    "#     # og filtrer efter fynske virksomheder\n",
    "#     # Hvis der ikke findes et tomt datasæt, så opret en tom Datafr\n",
    "#     try:\n",
    "#         old = pd.read_csv(\"csv/at.csv\",sep=\";\",keep_default_na=False)\n",
    "#         old.columns = old.columns.str.replace(\" \",\"\")\n",
    "#         old = old[(old[\"POSTNR\"] > lower) & (old[\"POSTNR\"] < upper) & (old[\"SMILEY\"] == \"rød\")]\n",
    "\n",
    "#         old = old.drop_duplicates()\n",
    "#         old = old.sort_values(\"NAVN\")\n",
    "#         old[\"id\"] = old[list(old.columns)].astype(str).sum(axis=1).map(hash)\n",
    "#         old_smiley_ids = list(dict.fromkeys(list(old[\"id\"])))\n",
    "#         old = old.reset_index(drop=True)\n",
    "        \n",
    "#     except:\n",
    "#         old = pd.DataFrame(list())\n",
    "#         old_smiley_ids = list()\n",
    "    \n",
    "#     try:\n",
    "#         # Opret tomme dataframes, hvor vi kan lægge henholdsvis tilføjede og fjernede smileyer\n",
    "#         added = pd.DataFrame()\n",
    "#         removed = pd.DataFrame()\n",
    "#         changes_found = False\n",
    "\n",
    "#         # Loop igennem nye smileyer for at se, om der eksisterer noget i de nye, som ikke eksisterede i det gamle\n",
    "#         # Hvis der gør, betyder det, at der er tilføjet en smiley\n",
    "#         for hit in new_smiley_ids:\n",
    "#             if not hit in old_smiley_ids:\n",
    "#                 new_row = new[new[\"id\"] == hit]\n",
    "#                 added = pd.concat([new_row, added])\n",
    "#                 changes_found = True\n",
    "\n",
    "\n",
    "#         # Loop igennem nye smileyer for at se, om der eksisterer noget i de nye, som ikke eksisterede i det gamle\n",
    "#         # Hvis der gør, betyder det, at der er fjernet en smiley. \n",
    "#         for hit in old_smiley_ids:\n",
    "#             if not hit in new_smiley_ids:\n",
    "#                 new_row = old[old[\"id\"] == hit]\n",
    "#                 removed = pd.concat([new_row, removed])\n",
    "#                 changes_found = True\n",
    "\n",
    "#         if changes_found is True:\n",
    "#             df.to_csv(\"csv/at.csv\",sep=\";\",index=False)\n",
    "            \n",
    "#         added.to_csv(\"csv/added_at.csv\",sep=\";\",index=False)\n",
    "#         removed.to_csv(\"csv/removed_at.csv\",sep=\";\",index=False)\n",
    "#     except:\n",
    "#         print(\"There was an error comparing new and old dataset\")\n",
    "\n",
    "# check_at_smiley(4999,6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6708424d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = []\n",
    "\n",
    "# Definer en header, der bliver sendt med GET-request\n",
    "header = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "# Sti til Arbejdstilsynets smiley-side\n",
    "url = \"https://websmiley.at.dk/websmiley/advancedsearchform.aspx\"\n",
    "\n",
    "# Send GET-request og hent Arbejdstilsynets smiley-side\n",
    "\n",
    "try:\n",
    "    r = requests.get(url,headers=header,timeout=8)\n",
    "    r.raise_for_status()\n",
    "except requests.exceptions.HTTPError as error:\n",
    "    errors.append(error)\n",
    "\n",
    "\n",
    "# Hvis status er OK parser scriptet indholdet, henter formData og tilføjer det til et dictionary\n",
    "if r.status_code == 200:\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "    viewstate = soup.select(\"#__VIEWSTATE\")[0]['value']\n",
    "    eventvalidation = soup.select(\"#__EVENTVALIDATION\")[0]['value']\n",
    "\n",
    "    formData = {\n",
    "        '__EVENTVALIDATION': eventvalidation,\n",
    "        '__VIEWSTATE': viewstate,\n",
    "        '__EVENTTARGET': '',\n",
    "        'companyName': 'Virksomhedens navn',\n",
    "        'cvrNr': 'CVR-nr.',\n",
    "        'pNr': 'P-nr.',\n",
    "        'ddlBrancheGrupper':0,\n",
    "        'ddlRegioner': 0,\n",
    "        'ddlSmiley':0,\n",
    "        'btnDownload': 'Download smileydata'   \n",
    "    }\n",
    "\n",
    "\n",
    "# Send POST-request, hvor den netop hentede formdata sendes med\n",
    "try:\n",
    "    r = requests.post(url, data=formData, headers=header)\n",
    "    r.raise_for_status()\n",
    "except requests.exceptions.HTTPError as error:\n",
    "    errors.append(error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "845b85a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    # Konverter responsdata til en string og indlæs i en DataFrame\n",
    "    # filtrer datasæt efter fynske virksomheder og røde smileyer\n",
    "    text = r.text\n",
    "    df = pd.read_csv(StringIO(text),sep=\";\",keep_default_na=False)\n",
    "    new = df\n",
    "    # Rens kolonnenavne for mellemrum og filtrer efter røde smileyer på fyn\n",
    "    new.columns = new.columns.str.replace(\" \",\"\")\n",
    "    new = new[(new[\"POSTNR\"] > lower) & (new[\"POSTNR\"] < upper) & (new[\"SMILEY\"] == \"rød\")]\n",
    "\n",
    "    # Fjern duplikerede rækker, sorter efter navn \n",
    "    # Lav ID-kolonne for det nye datasætaml alle IDs i en liste\n",
    "    new = new.drop_duplicates()\n",
    "    new = new.sort_values(\"NAVN\")\n",
    "    new[\"id\"] = new[list(new.columns)].astype(str).sum(axis=1).map(hash)\n",
    "    new = new.reset_index(drop=True)\n",
    "    new_smiley_ids = list(dict.fromkeys(list(new[\"id\"])))\n",
    "    \n",
    "except:\n",
    "    print(\"There was an error adding IDs to new dataset\")\n",
    "\n",
    "# Forsøg at indlæse tidligere datasæt i en dataframe\n",
    "# og filtrer efter fynske virksomheder\n",
    "# Hvis der ikke findes et tomt datasæt, så opret en tom Datafr\n",
    "try:\n",
    "    old = pd.read_csv(\"csv/at.csv\",sep=\";\",keep_default_na=False)\n",
    "    old.columns = old.columns.str.replace(\" \",\"\")\n",
    "    old = old[(old[\"POSTNR\"] > lower) & (old[\"POSTNR\"] < upper) & (old[\"SMILEY\"] == \"rød\")]\n",
    "\n",
    "    old = old.drop_duplicates()\n",
    "    old = old.sort_values(\"NAVN\")\n",
    "    old[\"id\"] = old[list(old.columns)].astype(str).sum(axis=1).map(hash)\n",
    "    old_smiley_ids = list(dict.fromkeys(list(old[\"id\"])))\n",
    "    old = old.reset_index(drop=True)\n",
    "\n",
    "except:\n",
    "    old = pd.DataFrame(list())\n",
    "    old_smiley_ids = list()\n",
    "\n",
    "try:\n",
    "    # Opret tomme dataframes, hvor vi kan lægge henholdsvis tilføjede og fjernede smileyer\n",
    "    added = pd.DataFrame()\n",
    "    removed = pd.DataFrame()\n",
    "    added_pnr = pd.DataFrame()\n",
    "    removed_pnr = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    changes_found = False\n",
    "    \n",
    "\n",
    "    # Loop igennem nye smileyer for at se, om der eksisterer noget i de nye, som ikke eksisterede i det gamle\n",
    "    # Hvis der gør, betyder det, at der er tilføjet en smiley\n",
    "    for hit in new_smiley_ids:\n",
    "        if not hit in old_smiley_ids:\n",
    "            new_row = new[new[\"id\"] == hit]\n",
    "            added = pd.concat([new_row, added])\n",
    "            changes_found = True\n",
    "\n",
    "\n",
    "    # Loop igennem nye smileyer for at se, om der eksisterer noget i de nye, som ikke eksisterede i det gamle\n",
    "    # Hvis der gør, betyder det, at der er fjernet en smiley. \n",
    "    for hit in old_smiley_ids:\n",
    "        if not hit in new_smiley_ids:\n",
    "            new_row = old[old[\"id\"] == hit]\n",
    "            removed = pd.concat([new_row, removed])\n",
    "            changes_found = True\n",
    "    \n",
    "    added_pnr_list = list()\n",
    "    removed_pnr_list = list()\n",
    "    \n",
    "    if len(added) > 0:\n",
    "        added_pnr_list = list(dict.fromkeys(list(added[\"PNR\"])))\n",
    "    if len(removed)>0:\n",
    "        removed_pnr_list = list(dict.fromkeys(list(removed[\"PNR\"])))\n",
    "    \n",
    "    for hit in added_pnr_list:\n",
    "        if not hit in removed_pnr_list:\n",
    "            new_row = added[added[\"PNR\"] == hit]\n",
    "            added_pnr = pd.concat([new_row, added_pnr])\n",
    "            changes_found = True\n",
    "            \n",
    "    for hit in removed_pnr_list:\n",
    "        if not hit in added_pnr_list:\n",
    "            new_row = removed[removed[\"PNR\"] == hit]\n",
    "            removed_pnr = pd.concat([new_row, removed_pnr])\n",
    "            changes_found = True\n",
    "            \n",
    "    if changes_found is True:\n",
    "        df.to_csv(\"csv/at.csv\",sep=\";\",index=False)\n",
    "\n",
    "    added.to_csv(\"csv/added_at.csv\",sep=\";\",index=False)\n",
    "    removed.to_csv(\"csv/removed_at.csv\",sep=\";\",index=False)\n",
    "    \n",
    "    added_pnr.to_csv(\"csv/added_pnr.csv\", sep=\";\", index=False)\n",
    "    removed_pnr.to_csv(\"csv/removed_pnd.csv\", sep=\";\",index=False)\n",
    "                    \n",
    "\n",
    "\n",
    "except:\n",
    "    print(\"There was an error comparing new and old dataset\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2aaca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b528c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6e6b8a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9067e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "700d9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2043cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
